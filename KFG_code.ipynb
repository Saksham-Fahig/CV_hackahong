{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aBMDUOCtdl"
      },
      "source": [
        "Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir1vGg--9hTE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/',force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXoHyqLECxRW"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSEpBDAW9lwb"
      },
      "source": [
        "import cv2\n",
        "from skimage.transform import downscale_local_mean\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import shutil as sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTusvElJ8_OC"
      },
      "source": [
        "**Label PROCESSING**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZnJv0ep8T6S"
      },
      "source": [
        "def convertTrainLabel():\n",
        "    df = pd.read_csv('./gdrive/MyDrive/CV Hackathon/Training Data/Labels/Train_DefectBoxes_PrithviAI.csv')\n",
        "\n",
        "    df['x_center'] = df['X']\n",
        "    df['y_center'] = df['Y']\n",
        "    df['classes'] = 0\n",
        "    from tqdm.auto import tqdm\n",
        "    import shutil as sh\n",
        "    df = df[[df.columns[0],'X', 'Y', 'W', 'H','x_center','y_center','classes']]\n",
        "    \n",
        "    index = list(set(df['  image_id']))\n",
        "    fault=[]\n",
        "    source = 'train'\n",
        "    if True:\n",
        "        for fold in [0]:\n",
        "            val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
        "            for name,mini in tqdm(df.groupby('  image_id')):\n",
        "                if name in val_index:\n",
        "                    path2save = 'val2017/'\n",
        "                else:\n",
        "                    path2save = 'train2017/'\n",
        "                name2 = name.split('.')[0]\n",
        "                if not os.path.exists('./gdrive/MyDrive/convertor/fold{}/labels/'.format(fold)+path2save):\n",
        "                    os.makedirs('./gdrive/MyDrive/convertor/fold{}/labels/'.format(fold)+path2save)\n",
        "                with open('./gdrive/MyDrive/convertor/fold{}/labels/'.format(fold)+path2save+name2+\".txt\", 'w+') as f:\n",
        "                    row = mini[['classes','x_center','y_center','W','H']].astype(float).values\n",
        "                    row = row.astype(str)\n",
        "                    for j in range(len(row)):\n",
        "                        text = ' '.join(row[j])\n",
        "                        f.write(text)\n",
        "                        f.write(\"\\n\")\n",
        "                with open('./gdrive/MyDrive/convertor/fold{}/labels/'.format(fold)+path2save+name2+\"r1.txt\", 'w+') as f:\n",
        "                    row = mini[['classes','x_center','y_center','W','H']].astype(float).values\n",
        "                    for i in range(len(row)):\n",
        "                        row[i][1] , row[i][2]= 1-row[i][1] , 1- row[i][2]\n",
        "                    row = row.astype(str)\n",
        "                    for j in range(len(row)):\n",
        "                        text = ' '.join(row[j])\n",
        "                        f.write(text)\n",
        "                        f.write(\"\\n\")\n",
        "                if not os.path.exists('./gdrive/MyDrive/convertor/fold{}/images/{}'.format(fold,path2save)):\n",
        "                    os.makedirs('./gdrive/MyDrive/convertor/fold{}/images/{}'.format(fold,path2save))\n",
        "                try:\n",
        "                    sh.copy(\"./gdrive/MyDrive/CV Hackathon/Training Data/Images Unzipped/Images/{}\".format(name),'./gdrive/MyDrive/convertor/fold{}/images/{}/{}'.format(fold,path2save,name))\n",
        "                except:\n",
        "                    \n",
        "                    try :\n",
        "                        sh.copy(\"./gdrive/MyDrive/CV Hackathon/Sample Images/Sample Images/bad_images/{}\".format(name),'./gdrive/MyDrive/convertor/fold{}/images/{}/{}'.format(fold,path2save,name))\n",
        "                    except:\n",
        "                        fault.append(name)\n",
        "    print(len(fault),fault)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWUTWBX3-LZH"
      },
      "source": [
        "**IMAGE AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHTPynMz-KwH"
      },
      "source": [
        "def rotate(source):\n",
        "    #this function rotate image by 180 degree  by this our amount of data samples get multiplied by 2 \n",
        "    path = source\n",
        "    kl = os.listdir(path)\n",
        "    for j in tqdm(kl):\n",
        "        fin = os.path.join(path,j)\n",
        "        img = cv2.imread(fin)\n",
        "        rotated_image1 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "        r1 = cv2.rotate(rotated_image1, cv2.ROTATE_90_CLOCKWISE)\n",
        "        fin,_=os. path. splitext(fin)\n",
        "        fin+='r1.jpg'\n",
        "        cv2.imwrite(fin,r1,[int(cv2.IMWRITE_JPEG_QUALITY),100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djFzG6Zz93zn"
      },
      "source": [
        "**IMAGE PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aPR8FZb93GB"
      },
      "source": [
        "def reshape_img(img):\n",
        "    #reshaping images form(1000,4096,3) =>(1024,1024) standard for yolo\n",
        "    \n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#converting image to black and white\n",
        "    factor_1 = 4\n",
        "    factor_2 = 1\n",
        "    gray=downscale_local_mean(gray, factors=(factor_2, factor_1)).astype(int)# shape of image(1000,1024)\n",
        "    #providing padding\n",
        "    gray =  cv2.copyMakeBorder(gray,12,12,0,0,cv2.BORDER_CONSTANT ,value = 0 )#shape of image(1024,10224))\n",
        "    return gray\n",
        "\n",
        "\n",
        "def imgprcs(img):\n",
        "    #Applying Edge detection\n",
        "    \n",
        "    edges = cv2.Canny(img,100,200)\n",
        "    return edges\n",
        "\n",
        "\n",
        "def sharp(img):\n",
        "    #Applying Sharpening of image by high pass filter\n",
        "    \n",
        "    krnl = np.array([[-1,-1,-1],\n",
        "                                [-1,9,-1],\n",
        "                                [-1,-1,-1]])\n",
        "    sharp_img= cv2.filter2D(img,-1,krnl)\n",
        "    return sharp_img\n",
        "\n",
        "\n",
        "def preprocessing(source,destination):\n",
        "    path_s = source\n",
        "    path_d = destination\n",
        "    list_itm = os.listdir(source) # this will contain list of images\n",
        "    for j in tqdm(list_itm):\n",
        "        \n",
        "        #converting them to jpg format for saving space \n",
        "          \n",
        "        img_pth = os.path.join(path_s,j)\n",
        "        fin,_=os.path.splitext(j)\n",
        "        fin+='.jpg'\n",
        "        fin = os.path.join(destination,fin)\n",
        "        img = cv2.imread(img_pth)\n",
        "        img = reshape_img(img)\n",
        "        cv2.imwrite(fin,img,[int(cv2.IMWRITE_JPEG_QUALITY),100])\n",
        "        img = cv2.imread(fin)\n",
        "        img = sharp(img)\n",
        "        img = imgprcs(img)       \n",
        "        cv2.imwrite(fin,img,[int(cv2.IMWRITE_JPEG_QUALITY),100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3P8pIYc_Pwn"
      },
      "source": [
        "**Training By YoLo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgudusZVBWIU"
      },
      "source": [
        "Importing yolo--version-5 library from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9DwPuOH_Oyo"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOemrtgABhFs"
      },
      "source": [
        "Installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSHMDQYM9zS1"
      },
      "source": [
        "%cd yolov5\n",
        "%pip install -qr ./requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l80yHSaBsU4"
      },
      "source": [
        "Training our Yolo model 10 epochs with inital pre trained wieghts of yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEb4_5mr__rQ"
      },
      "source": [
        "!python train.py --img 1024 --batch 6 --epochs 10 --data ../gdrive/MyDrive/convertor/fold1/data.yaml --weights yolov5l.pt --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3UcwnMBBzVx"
      },
      "source": [
        "Validating the best model form the above epochs with the max allowed overlap of 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jUbKvPzADIr"
      },
      "source": [
        "!python val.py --img 1024 --data ../gdrive/MyDrive/convertor/fold0/data.yaml --weights ./runs/train/exp/weights/best.pt --iou 0.2 --half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM2JYKpHB2uR"
      },
      "source": [
        "running the provided dataset with the best fitted model keeping threshold as 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcBXz_mZAMDx"
      },
      "source": [
        "!python detect.py --img 1024 --source ../test001 --iou-thres 0.2 --save-txt --weights ./runs/train/exp22/weights/best.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv4URdUFCY9c"
      },
      "source": [
        "**converting the output to CSV format for submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B05hmIguAbLA"
      },
      "source": [
        "image_id=[]\n",
        "X=[]\n",
        "Y=[]\n",
        "H=[]\n",
        "W=[]\n",
        "for i in os.listdir('detect\\exp2\\labels'):\n",
        "    filename = os.path.join('detect\\exp2\\labels',i)\n",
        "    with open (filename ,'r') as rf:\n",
        "        for line in rf:\n",
        "            ints = line.split()\n",
        "            i,_=os. path. splitext(i)\n",
        "            i+='.png'\n",
        "            image_id.append(i)\n",
        "            X.append(ints[1])\n",
        "            Y.append(ints[2])\n",
        "            H.append(ints[3])\n",
        "            W.append(ints[4])\n",
        "\n",
        "dic ={}\n",
        "dic['image_id'] = image_id\n",
        "dic['X'] =X\n",
        "dic['Y'] =Y\n",
        "dic['H'] =H\n",
        "dic['W'] =W\n",
        "\n",
        "df = pd.DataFrame(dic)\n",
        "\n",
        "df.to_csv('file1.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iheUaJ2RAm-s"
      },
      "source": [
        "defectlist= list(df['image_id'])\n",
        "allfile = os.listdir('test')\n",
        "res=[]\n",
        "for i in allfile:\n",
        "    if i in defectlist:\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(0)\n",
        "    \n",
        "    dic2 = {}\n",
        "dic2['images_id']=allfile\n",
        "dic2['defect_flag']=res\n",
        "\n",
        "df2 = pd.DataFrame(dic2)\n",
        "df2.to_csv('file2.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}